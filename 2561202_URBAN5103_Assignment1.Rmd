---
title: '**Transport Planning Method Assignment 1**'
author: "Wanying Sun(2516202S)"
date: "2/9/2021"
output:
  html_document:
    theme: cosmo
    highlight: monochrome
    toc: yes
    toc_float: yes
    toc_depth: 5
  pdf_document:
    toc: yes
    toc_depth: '5'
---
<style type="text/css">
.main-container {
  max-width: 1800px;
  margin-left: auto;
  margin-right: auto;
}
</style>
**(word count: 1130 words, excluding questions)**
<br />
<br />
```{r setup, include=FALSE}
knitr::opts_chunk$set(fig.align = 'center', out.width = '80%', echo = TRUE)
```

```{r data, include = FALSE}
library(tidyverse)
library(dplyr)
library(readr)
library(kableExtra)
library(gridExtra)
```

### **1. Download travel survey data and codebook from:  https://www.psrc.org/travel-surveys-spring-2014-household-survey.**

##### **a) Calculate total travel distance (find the distance variable from codebook) for each person (personID) and household (hhid) (save them as distance_person and distance_household, respectively; use a hhsurvey-trips file). Provide a summary statistics of total travel distance variable for person and household (Please remove all missing or unexpected data).**
<br />

```{r Question 1a, select travel distance for each person, warning = FALSE}
hhsurvey_trips <- read.csv("/Volumes/SALMON/Salmon/UofG/Semester2/TPM/Assignment1/2014-pr3-hhsurvey-trips.csv")

## Total travel distance for each person (personID)
distance_person <- hhsurvey_trips %>% 
  select(personID, gdist)
summary(distance_person $ gdist)
```
**Data cleaning description**<br />
**The summary table shows that there exist some NA variables and 0 values of variable gdist. Before cleaning the data, we could find that the description of Trip file (2014_readme file, downloaded from https://www.psrc.org/sites/default/files/2014-readme.pdf) showed that 'If a person took no trips on the target day, that person had no record in the Trip file but did in the Persons file'. In terms of the 0 values, it means the person did not take trips and had no records (or the record is 0) on the target day in Trip file, however, the person/household had the record in the Persons file which meant that 0 value was not an error in this data set. Besides, we try not to discard the number of samples which might have influence to the population estimation. Particularly, the distance was filtered from 0 to 350, which means that one full fuel tank driving distance is around 350 ~ 370 miles. Thus, the data cleaning process of gdist will only discard the NA and -99.000 values whilst keep the values more than or equals to 0 and less than and equals to 350.**
<br />
<br />
```{r Question 1a, Calculate total travel distance for each person, warning = FALSE}
## Total travel distance for person :
distance_person <- distance_person %>%
  filter(gdist >= 0 & gdist <= 350) %>%
  drop_na(gdist) %>%
  group_by(personID) %>%
  summarise(distance_person = sum(gdist)) %>%
  arrange(distance_person)
summary(distance_person)
distance_person
```

```{r Question 1a, Calculate total travel distance for each household, warning = FALSE}
## Total travel distance for each household (hhid):
distance_household <- hhsurvey_trips %>% 
  select(hhid, gdist)
summary(distance_household $ gdist)
# Then we do the same data cleaning process as person to household below
# In household data, we do not set an upper limitation for the travel distance, 
# because we could not tell how many travel family members of each family every day, 
# there is not a baseline for the upper limit.
distance_household <- distance_household %>%
  filter(gdist >= 0) %>% 
  drop_na(gdist) %>%
  group_by(hhid) %>%
  summarise(distance_household = sum(gdist))%>%
  arrange(distance_household)
summary(distance_household)
distance_household
di_all <- rbind(dim(distance_person), dim(distance_household))
rownames(di_all) <- c("Person", "Household")
colnames(di_all) <- c("Record numbers", "Variable numbers")
kbl(di_all, 
    caption = "Table 1.1(a) Number of records of person and household",
    align = "c") %>%
   kable_styling(bootstrap_options = "striped",
                 font_size = 15) %>%
  kable_classic(full_width = F, html_font = "Calibri")
```
**Total travel distance for each person and household table description:**
<br />Overall, the tables above gave the total distance information of each person and household respectively. 
<br />
<br />In 'Total travel distance for person' table, the farthest travel distance was 970.8 miles and the least was 0 among the 10816 records. We could notice that there were eight people (IDs are 1410150601, 1410305603, 1410369501, 1410429602, 1410432403, 1410455701, 1410455702, 1410463602 respectively) with 0 travel distance which meant that those people did not have travel records on the target day.
<br />
<br />Similarly, there were 5813 households observations in 'Total travel distance for each household (hhid)' table, the longest travel distance was 7372.68 miles and the shortest was 0 miles. 




```{r Question 1a, Summary statistics of total travel distance variable for person and household, warning = FALSE}
summary_person <- summary(distance_person $ distance_person)
summary_household <- summary(distance_household $ distance_household)
summary_statistics <- rbind(summary_person, summary_household)
rownames(summary_statistics) <- c("Summary to person", "Summary to household")
kbl(summary_statistics, 
    caption = "Table 1.2(a) Summary statistics of total travel distance variable for household",
    align = "c") %>%
   kable_styling(bootstrap_options = "striped",
                 font_size = 15) %>%
    kable_classic(full_width = F, html_font = "Calibri")
```
**Q1(a) Summary statistics of table1.2:**
<br />Table 1.2(a) showed the statistics information of the total travel distance of each person and household. Overall, all the travel distance of households were higher than each person. Both minimum values are 0 whereas households got longer max travel distance, accounting for 7372.68, and that of person's was 970.80. The mean distance and the median of both were about 71 and 25, 32 and 16 respectively.
<br />
<br />
<br />


##### **b)	Create new data (household) that includes household id, number of vehicles, household size, number of workers in household. Please remove all missing values (including prefer not to answer). Display summary statistics of all variables in the data except id.  Find its dimensions.**
<br />
```{r Question 1b, Display summary statistics of all variables in the data except id, warning = FALSE}
hhsurvey_households <- read.csv("/Volumes/SALMON/Salmon/UofG/Semester2/TPM/Assignment1/2014-pr3-hhsurvey-households.csv")
## Select household id, number of vehicles, household size, number of workers from household:
household <- hhsurvey_households %>% 
  select(hhid, vehicle_count, hhsize, numworkers)
summary(household)
household <- household %>%      #filtered household data
  filter(hhid >= 0, vehicle_count >= 0, hhsize >= 0, numworkers >= 0)
summary_exceptID <- rbind(summary(household $ vehicle_count), summary(household $ hhsize), summary(household $ numworkers))
rownames(summary_exceptID) <- c("Number of vehicles", "Household size", "Number of workers")
kbl(summary_exceptID, 
    caption = "Table 1.1(b) Summary statistics of number of vehicles, household size, number of workers in household",
    align = "ccc") %>%
   kable_styling(bootstrap_options = "striped",
                 font_size = 15) %>%
  kable_classic(full_width = T, html_font = "Calibri")
## Creat a new dataset of all variables except ID and print out the dimensions:
all_exceptID_data <- household %>%
  select(-hhid)
da <- dim(all_exceptID_data)
daty <- as.data.frame(da)
rownames(daty) <- c("Number of objections", "Number of variables")
colnames(daty) <- c("Number")
kbl(daty, 
    caption = "Table 1.2(b) Dimensions of number of vehicles, household size, and number of workers in household",
    align = "ccc") %>%
   kable_styling(bootstrap_options = "striped",
                 font_size = 15) %>%
    kable_classic(full_width = T, html_font = "Calibri")
```
**Q1(b) Tables description:**
<br />Table 1.1(b) showed the summary statistics of number of vehicles, household size, and number of workers in household. Overall, both the min values of number of vehicles and number of workers are zero as well as the median values are 2. All three variables have the same 1st Qu and the 3rn Qu (1 and 2 respectively). However, Household size accounts for the largest mean value (about 2.01) whereas the others are around 1.13 and 1.57 respectively.
<br />
<br />Table 1.2(b) shows that the number of variable is 3 (number of vehicles, household size, and number of workers in household respectively), and the number of observations is 6,036.
<br />
<br />
<br />


##### **c)	Display the data contained in the first 10 rows and in all columns except column 4.** 
```{r Question 1c,	Display the data contained in the first 10 rows and in all columns except column 4 of household data, warning = FALSE}
display_household <- as.data.frame(household[1:10,-4])
kbl(display_household, 
    caption = "Table 1.1(c) The first 10 rows of household",
    col.names = c("Household ID", "Number of Vehicles", "Household size"),
    align = "ccc") %>%
   kable_styling(bootstrap_options = "striped",
                 font_size = 15) %>%
  kable_classic(full_width = T, html_font = "Calibri")
```

<br />
<br />
<br />


##### **d)	Merge new data (household) and total travel distance for household (distance_household). What is the correlation between total travel distance and household size? Draw a histogram of log (total travel distance). Order the data by total travel distance, smallest to largest. (for this problem, please google to find proper functions. You can also find a way to insert title and axis labels).** 
```{r Question 1d, warning = FALSE}
household_merge <- merge(household, distance_household) %>%
  arrange(distance_household)
cor(household_merge $ distance_household, household_merge $ hhsize)

ggplot(household_merge, aes(x = log(household_merge $ distance_household))) +
  labs(x = "log(Total Travel Distance)", 
       y = "count",
       title = "Distribution of total travel distance of household",
       subtitle = "Logarithm Scale",
       caption = "Data source: 2014 Household survey, PSRC") +
  geom_histogram(alpha = 0.8, 
                 position = "identity", 
                 bins = 100,
                 fill = "steelblue") +
  scale_fill_discrete(h = c(250, 10)) +
  theme(plot.title = element_text(colour = "black", size = 15, face = "bold", hjust = 0.5), 
        plot.caption = element_text(colour = "steelblue", size = 10, face = "italic", hjust = 1),
        plot.subtitle = element_text(colour = "grey", size = 9, face = "bold"),
        axis.text.x = element_text(face = "bold", size = 8), 
        axis.text.y = element_text(face = "bold", size = 8))
```

**Q1(d) Statistics description:**
<br />The person's product-moment correlation summary showed the correlation between total travel distance and household size is 0.1054564. Compare the p-value with a significance level(α), p-value(7.563^(-16)) is smaller than 0.05(α), the null hypothesis will be rejected; and we are 95% confident that the population mean lies between 0.07997 and 0.13081.
<br />
<br />
<br />
<br />
<br />


### **2. Please run a multiple linear regression of your own choosing. You can choose any dependent variable that you are interested in.**
##### **a) Write your equation**
The equation for this multiple linear regression model could be:
$$Y_i\sim N(\alpha+\beta_1*X_1{_i}+\beta_2*X_2{_i}+\beta_3*X_3{_i}+\beta_4*X_4{_i}+\beta_5*X_5{_i}, \sigma^2),\ i = 1, 2,..., 5
$$
$X_1: gtime\ (driving\ travel\ time\ (minutes)\ from\ origin\ to\ destination)\\X_2:{trip\underline{ }dur\underline{ }reported}\ (trip\ duration\ in\ minutes)\\X_3: {implied\underline{ }speed\underline{ }mph}\ (implied\ speed\ (miles/hour))\\X_4:{travelers\underline{ }total}\ (total\ number\ of\ travelers\ on\ trip\ including\ self)\\X_5:{mtime\underline{ }day}\ (peak/off-peak\ periods\ for\ MTIME)$

The interpretation is log(people's travel distance) in Seattle for 2014 PSRC investigation follows the normal distribution, and has a mean $\alpha+\beta_1*X_1{_i}+\beta_2*X_2{_i}+\beta_3*X_3{_i}+\beta_4*X_4{_i}+\beta_5*X_5{_i}$, a standard deviation $\sigma$.
<br />
<br />
<br />

##### **b) Provide a detailed explanation of your variable choice (i.e., independent variables) with the expected signs of these variables**
```{r Question 2(b), variable selection and data cleaning, warning = FALSE}
hhsurvey_trips <- read.csv("/Volumes/SALMON/Salmon/UofG/Semester2/TPM/Assignment1/2014-pr3-hhsurvey-trips.csv")
dim(hhsurvey_trips)

hhsurvey_trips <- hhsurvey_trips %>% 
  select("hhid", "mtime_day", "gtime", "trip_dur_reported", "implied_speed_mph", "travelers_total", "gdist")
summary(hhsurvey_trips)

# Cleaning the data and drop the NA values
hhsurvey_trips <- hhsurvey_trips %>% 
  drop_na() %>% 
  filter(gtime >= 0, implied_speed_mph <= 85, trip_dur_reported <= 180) %>% # The survey data included some measningless data such as some of the driving travel time from OD (gtime) is less than 0 which means that those data should not be taken account into the analysis.
  group_by(hhid) 
summary(hhsurvey_trips)

dim(hhsurvey_trips)

# Make dummy variables: Peak/Off-Peak periods for MTIME (mtime_day)
hhsurvey_trips <- hhsurvey_trips %>% 
  mutate(mtime = factor(mtime_day))
hhsurvey_trips

summary(hhsurvey_trips)
attach(hhsurvey_trips)

category <- c("Dependent Variable", "Independent Variables", "Independent Variables", "Independent Variables", "Independent Variables", "Independent Variables")
variable <- c("gdist", "trip_dur_reported", "gtime", "travelers_total", "mtime_day", "implied_speed_mph")
description <- c("Driving distance (miles) from origin to destination", "Trip duration in minutes", "Driving travel time (minutes) from origin to destination", "Total number of travelers on trip including self", "Peak/Off-Peak periods for MTIME", "Implied speed (miles per hour): Driving distance over reported travel time")
type <- c("Numeric", "Numeric", "Numeric", "Numeric", "Numeric", "Numeric")
measurement <- c("Scale", "Nominal", "Nominal", "Nominal", "Nominal", "Nominal")
meth <- c("derived (Google estimate)", "derived", "derived (Google estimate)", "Questionnaire", "assigned", "derived")
tb <- cbind(category, variable, description, type, measurement, meth)
colnames(tb) <- c("Category", "Variable name", "Description", "Type", "Measurement", "Attain method")
kbl(tb, 
    caption = "Table 2.1(b) Variable description and summary",
    align = "c") %>%
   kable_styling(bootstrap_options = "striped",
                 font_size = 15) %>%
  kable_classic(full_width = T, html_font = "Calibri") %>%
  column_spec(2, bold = T) %>%
  collapse_rows(columns = 1:2, valign = "middle")
```

<br />The table 2.1(b) indicates the meaning and the attribute of each variables. I chose gdist as dependent variables, trip_dur_reported, gtime, travelers_total, mtime_day, and implied_speed_mph as independent variables. Overall, all five independent variables have direct or indirect influence on the driving distance, such as the trip duration time (trip_dur_reported) might show the sign that the more trip duration time the traveler spent, the farther the traveler will go. Similarly, take implied speed (implied_speed_mph, miles/h) as another example (Kim & Van, 2011), the driving distance should be proportionate to the increasing travel speed. Ryosoke (2018) used the number of travelers as a factor and explored the relation between daily travel distance. However, some of these independent variables might coincide such as driving travel time and trip duration time, both are time length variables but driving travel time is one particular range of time for OD (origin and destination).
<br />
<br />
<br />


##### **c) Test the validity of the model (F-test) and calculate $R^2$. Explain the theoretical foundation of the test and $R^2$ based on the formula**
```{r Question 2(c), multiple regresison model R square and F value, warning = FALSE}
# multiple regression model
yi <- log(gdist) 
n <- length(yi)
new_data <- data.frame(yi, 
                       gtime, trip_dur_reported, implied_speed_mph, travelers_total, mtime)
new_data1 <- data.frame(yi, 
                        gtime, trip_dur_reported, implied_speed_mph, travelers_total, mtime_day)

new_data<-new_data[which(new_data $ yi != "-Inf"),] # The antilogarithm has to be more than 0, or the logarithmic function will be -Inf which means useless.
new_data1<-new_data1[which(new_data1 $ yi!= "-Inf"),]
n <- length(new_data$y) #for calculating f-value

pairs(new_data) 
cor(new_data1)
fit_d <- lm(yi ~ gtime + trip_dur_reported + implied_speed_mph + travelers_total + mtime, 
            data = new_data)
summary(fit_d)

# R square：
residual_m <-resid(fit_d)
SSE <-sum(residual_m^2)
SSR <- sum((predict(fit_d) - mean(new_data $ yi))^2)
SST <- sum((new_data $ yi - mean(new_data $ yi))^2)
R_sq_m <- 1-(SSE/SST)
R_sq_m

# Adjusted R-squared: The adjusted R-squared is a modified version of R-squared that accounts for predictors that are not significant in a regression model. In other words, the adjusted R-squared shows whether adding additional predictors improve a regression model or not. In this model, the value of adjusted R square is 0.8090955, which is a bit less than R square (0.8090634).
R_sq_m_a <- 1-(n-1)*(1-R_sq_m)/(n-8-1)
R_sq_m_a

# F-test
fvalue <- (SSR / 8) / (SSE / (n - 8 - 1))
fvalue


# Variance
sigma_sq <- SSE/(n-8-1) 
sigma <- sqrt(sigma_sq)
sigma
sigma_sq
```

According to the summary(fit_d), the formula of this multiple linear regression model is:

$$Y_i\sim N(-1.0858-0.0136X_1{_i}+0.0433X_2{_i}+0.0904X_3{_i}-0.0073X_4{_i}-0.1223X_5{_i}-0.0448X_6{_i}\\-0.0895X_7{_i}-0.1638X_8{_i}, \ 0.4009),\ i = 1, 2,..., 5$$

$X_1: gtime\ (driving\ travel\ time\ (minutes)\ from\ origin\ to\ destination)\\X_2:{trip\underline{ }dur\underline{ }reported}\ (trip\ duration\ in\ minutes)\\X_3: {implied\underline{ }speed\underline{ }mph}\ (implied\ speed\ (miles/hour))\\X_4:{travelers\underline{ }total}\ (total\ number\ of\ travelers\ on\ trip\ including\ self)\\X_5:{mtime\underline{ }day=2}\ (peak/off-peak\ periods\ for\ MTIME)\\X_6:{mtime\underline{ }day=3}\ (peak/off-peak\ periods\ for\ MTIME)\\X_7:{mtime\underline{ }day=4}\ (peak/off-peak\ periods\ for\ MTIME)\\X_8:{mtime\underline{ }day=5}\ (peak/off-peak\ periods\ for\ MTIME)$

<br />
<br />
From the the summary(fit_d), we could see that the $R^2$ = 0.8091, which was calculated by 1-(SSE/SST). SSE is the sum of squares for error which is a measure of the discrepancy between the data and an estimation model, and SST is the sum of squares total. $R^2$ is a statistical measure that represents the proportion of the variance for a dependent variable that is explained by an independent variable or variables in a regression model. In this model, the $R^2$ is 0.8091 which means that the model could explained about 80.91% of the dependent variable.
<br />
F-value is used for the validity test of the linear regression model and is calculated based on the SSR and SSE: $$F-value: \frac{\frac{SSR}{Df_{SSR}}}{\frac{SSE}{Df_{SSE}}} \sim F_{1,\ n-k-1}
$$
The null hypothesis($H_0$) is that all $\beta$ (coefficients) equal to zero. If this is true, it means that our model is invalid. The F value in this model is 25230 which is larger than 0. Therefore, we can reject the null hypothesis which means the model is valid.
<br />
<br />
<br />

##### **d) Check the model assumptions**
```{r Question 2(d), check the assumptions, warning = FALSE, message=FALSE}
par(mfrow = c(2, 2))
plot(fit_d)
library(MASS)
library(car)
ncvTest(fit_d) # Constant variance: null hypothesis of homoscedasticity
durbinWatsonTest(fit_d)

# VIF
vif(fit_d, digit = 4)     # Are the values greater than 2?
```
The null hypothesis and alternative hypothesis are:<br />
$H_0:$ The regression model will not be influenced by independent variables, $\beta=0$<br />
$H_1:$The regression model will be influenced by independent variables, $\beta\neq0$<br />
<br />
Then we check each assumptions:
<br /> (1) Redisual mean is zero, the expected value of $E(Y_i|X_i)$ should be $\alpha + \beta_i X_i$.<br />
From the residual VS fitted plot, we could see that the values are not evenly distributed on both side of the line y = 0, there is an obvious fluctuation of the red line, this shows that this assumption is not true;
<br /> (2) Homoscedasticity: the $\sigma_2$ of each $Var(e_i)$ should be the same.<br />
The Scale-location plot shows that the values are not evenly distributed around the red baseline, which means for each x value, the $\sigma_2$ is different. Besides, from the ncvTest result, we could see that the P-value is less than 0.05. Therefore, we can reject the null hypothesis and conclude that the homoscedasticity exists;
<br /> (3) Errors are independent: all the observations should be independent.<br />
$e_i)$ is the random error term, which means the difference between estimated value and the real value. From the Dubin-Waston test output we can see that the test statistic is 1.395122 and the corresponding p-value is 0. Since the p-value is less than 0.05, we can reject the null hypothesis and conclude that the residuals in this regression model are autocorrelated.
<br /> (4) Normality: $e_i\sim N(0, \sigma^2)$, $e_i)$ follows the normal distribution, has the mean 0, and the standardized deviation $\sigma^2$.<br />
The Normal Q-Q plot illustrates that the values are not closed to the dotted line, which means the values are dispersed. Therefore this assumption is not true.<br />
<br />About the multicollinearity, we can see that the VIF for gtime, trip_dur_reported, and implied_speed_mph are greater than 2, which is potentially concerning.
<br />
<br />
<br />


### **Reference**

<br />Abe, R. and Kato, H., 2018. Long-run studies of daily travel: methodological review and convergence of distance traveled per capita across cities. *Transport Reviews*, **39**(4), pp. 443-462.<br />
Kim, N. and Van Wee, B., 2011. The relative importance of factors that influence the break-even distance of intermodal freight transport systems. *Journal of Transport Geography*, **19**(4), pp.859-875.